,제목,저자,출판일,기관,초록
0,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
1,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
2,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
3,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
4,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
5,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
6,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
7,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
8,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
9,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
10,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
11,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
12,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
13,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
14,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
15,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
16,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
17,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
18,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
19,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
20,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
21,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
22,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
23,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
24,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
25,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
26,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
27,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
28,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
29,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
30,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
31,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
32,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
33,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
34,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
35,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
36,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
37,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
38,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
39,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
40,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
41,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
42,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
43,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
44,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
45,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
46,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
47,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
48,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
49,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
50,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
51,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
52,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
53,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
54,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
55,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
56,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
57,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
58,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
59,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
60,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
61,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
62,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
63,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
64,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
65,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
66,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
67,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
68,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
69,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
70,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
71,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
72,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
73,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
74,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
75,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
76,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
77,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
78,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
79,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
80,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
81,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
82,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
83,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
84,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
85,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
86,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
87,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
88,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
89,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
90,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
91,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
92,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
93,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
94,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
95,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
96,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
97,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
98,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
99,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
100,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
101,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
102,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
103,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
104,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
105,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
106,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
107,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
108,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
109,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
110,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
111,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
112,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
113,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
114,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
115,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
116,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
117,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
118,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
119,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
120,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
121,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
122,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
123,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
124,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
125,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
126,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
127,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
128,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
129,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
130,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
131,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
132,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
133,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
134,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
135,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
136,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
137,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
138,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
139,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
140,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
141,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
142,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
143,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
144,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
145,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
146,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
147,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
148,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
149,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
150,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
151,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
152,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
153,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
154,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
155,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
156,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
157,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
158,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
159,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
160,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
161,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
162,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
163,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
164,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
165,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
166,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
167,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
168,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
169,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
170,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
171,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
172,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
173,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
174,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
175,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
176,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
177,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
178,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
179,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
180,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
181,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
182,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
183,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
184,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
185,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
186,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
187,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
188,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
189,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
190,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
191,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
192,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
193,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
194,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
195,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
196,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
197,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
198,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
199,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
200,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
201,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
202,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
203,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
204,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
205,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
206,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
207,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
208,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
209,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
210,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
211,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
212,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
213,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
214,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
215,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
216,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
217,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
218,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
219,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
220,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
221,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
222,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
223,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
224,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
225,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
226,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
227,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
228,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
229,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
230,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
231,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
232,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
233,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
234,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
235,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
236,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
237,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
238,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
239,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
240,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
241,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
242,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
243,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
244,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
245,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
246,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
247,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
248,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
249,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
250,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
251,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
252,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
253,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
254,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
255,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
256,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
257,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
258,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
259,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
260,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
261,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
262,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
263,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
264,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
265,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
266,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
267,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
268,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
269,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
270,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
271,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
272,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
273,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
274,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
275,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
276,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
277,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
278,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
279,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
280,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
281,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
282,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
283,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
284,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
285,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
286,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
287,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
288,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
289,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
290,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
291,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
292,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
293,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
294,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
295,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
296,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
297,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
298,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
299,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
300,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
301,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
302,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
303,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
304,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
305,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
306,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
307,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
308,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
309,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
310,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
311,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
312,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
313,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
314,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
315,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
316,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
317,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
318,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
319,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
320,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
321,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
322,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
323,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
324,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
325,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
326,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
327,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
328,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
329,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
330,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
331,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
332,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
333,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
334,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
335,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
336,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
337,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
338,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
339,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
340,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
341,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
342,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
343,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
344,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
345,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
346,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
347,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
348,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
349,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
350,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
351,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
352,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
353,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
354,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
355,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
356,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
357,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
358,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
359,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
360,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
361,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
362,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
363,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
364,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
365,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
366,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
367,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
368,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
369,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
370,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
371,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
372,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
373,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
374,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
375,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
376,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
377,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
378,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
379,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
380,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
381,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
382,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
383,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
384,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
385,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
386,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
387,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
388,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
389,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
390,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
391,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
392,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
393,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
394,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
395,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
396,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
397,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
398,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
399,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
400,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
401,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
402,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
403,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
404,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
405,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
406,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
407,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
408,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
409,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
410,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
411,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
412,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
413,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
414,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
415,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
416,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
417,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
418,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
419,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
420,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
421,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
422,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
423,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
424,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
425,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
426,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
427,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
428,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
429,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
430,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
431,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
432,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
433,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
434,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
435,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
436,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
437,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
438,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
439,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
440,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
441,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
442,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
443,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
444,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
445,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
446,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
447,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
448,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
449,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
450,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
451,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
452,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
453,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
454,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
455,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
456,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
457,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
458,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
459,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
460,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
461,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
462,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
463,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
464,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
465,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
466,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
467,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
468,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
469,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
470,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
471,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
472,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
473,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
474,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
475,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
476,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
477,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
478,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
479,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
480,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
481,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
482,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
483,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
484,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
485,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
486,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
487,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
488,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
489,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
490,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
491,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
492,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
493,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
494,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
495,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
496,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
497,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
498,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
499,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
500,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
501,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
502,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
503,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
504,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
505,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
506,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
507,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
508,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
509,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
510,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
511,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
512,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
513,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
514,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
515,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
516,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
517,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
518,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
519,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
520,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
521,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
522,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
523,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
524,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
525,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
526,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
527,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
528,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
529,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
530,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
531,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
532,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
533,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
534,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
535,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
536,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
537,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
538,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
539,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
540,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
541,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
542,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
543,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
544,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
545,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
546,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
547,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
548,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
549,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
550,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
551,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
552,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
553,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
554,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
555,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
556,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
557,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
558,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
559,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
560,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
561,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
562,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
563,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
564,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
565,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
566,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
567,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
568,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
569,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
570,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
571,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
572,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
573,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
574,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
575,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
576,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
577,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
578,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
579,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
580,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
581,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
582,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
583,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
584,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
585,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
586,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
587,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
588,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
589,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
590,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
591,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
592,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
593,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
594,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
595,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
596,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
597,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
598,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
599,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
600,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
601,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
602,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
603,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
604,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
605,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
606,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
607,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
608,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
609,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
610,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
611,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
612,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
613,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
614,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
615,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
616,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
617,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
618,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
619,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
620,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
621,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
622,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
623,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
624,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
625,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
626,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
627,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
628,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
629,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
630,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
631,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
632,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
633,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
634,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
635,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
636,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
637,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
638,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
639,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
640,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
641,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
642,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
643,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
644,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
645,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
646,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
647,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
648,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
649,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
650,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
651,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
652,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
653,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
654,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
655,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
656,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
657,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
658,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
659,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
660,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
661,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
662,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
663,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
664,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
665,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
666,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
667,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
668,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
669,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
670,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
671,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
672,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
673,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
674,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
675,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
676,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
677,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
678,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
679,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
680,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
681,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
682,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
683,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
684,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
685,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
686,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
687,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
688,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
689,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
690,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
691,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
692,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
693,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
694,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
695,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
696,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
697,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
698,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
699,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
700,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
701,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
702,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
703,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
704,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
705,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
706,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
707,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
708,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
709,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
710,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
711,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
712,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
713,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
714,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
715,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
716,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
717,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
718,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
719,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
720,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
721,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
722,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
723,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
724,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
725,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
726,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
727,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
728,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
729,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
730,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
731,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
732,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
733,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
734,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
735,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
736,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
737,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
738,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
739,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
740,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
741,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
742,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
743,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
744,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
745,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
746,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
747,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
748,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
749,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
750,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
751,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
752,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
753,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
754,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
755,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
756,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
757,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
758,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
759,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
760,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
761,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
762,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
763,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
764,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
765,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
766,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
767,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
768,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
769,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
770,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
771,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
772,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
773,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
774,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
775,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
776,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
777,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
778,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
779,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
780,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
781,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
782,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
783,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
784,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
785,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
786,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
787,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
788,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
789,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
790,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
791,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
792,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
793,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
794,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
795,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
796,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
797,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
798,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
799,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
800,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
801,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
802,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
803,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
804,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
805,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
806,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
807,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
808,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
809,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
810,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
811,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
812,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
813,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
814,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
815,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
816,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
817,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
818,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
819,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
820,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
821,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
822,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
823,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
824,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
825,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
826,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
827,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
828,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
829,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
830,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
831,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
832,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
833,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
834,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
835,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
836,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
837,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
838,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
839,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
840,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
841,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
842,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
843,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
844,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
845,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
846,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
847,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
848,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
849,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
850,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
851,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
852,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
853,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
854,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
855,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
856,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
857,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
858,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
859,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
860,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
861,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
862,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
863,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
864,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
865,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
866,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
867,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
868,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
869,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
870,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
871,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
872,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
873,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
874,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
875,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
876,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
877,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
878,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
879,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
880,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
881,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
882,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
883,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
884,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
885,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
886,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
887,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
888,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
889,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
890,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
891,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
892,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
893,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
894,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
895,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
896,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
897,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
898,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
899,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
900,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
901,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
902,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
903,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
904,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
905,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
906,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
907,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
908,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
909,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
910,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
911,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
912,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
913,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
914,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
915,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
916,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
917,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
918,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
919,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
920,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
921,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
922,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
923,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
924,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
925,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
926,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
927,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
928,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
929,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
930,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
931,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
932,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
933,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
934,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
935,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
936,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
937,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
938,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
939,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
940,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
941,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
942,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
943,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
944,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
945,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
946,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
947,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
948,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
949,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
950,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
951,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
952,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
953,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
954,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
955,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
956,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
957,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
958,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
959,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
960,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
961,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
962,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
963,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
964,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
965,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
966,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
967,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
968,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
969,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
970,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
971,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
972,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
973,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
974,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
975,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
976,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
977,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
978,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
979,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
980,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
981,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
982,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
983,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
984,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
985,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
986,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
987,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
988,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
989,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
990,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
991,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
992,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
993,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
994,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
995,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
996,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
997,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
998,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
999,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
1000,인공지능 철학 국내연구 동향 분석 —인공지능 철학의 생장점에서—,김형주 /Hyeongjoo Kim,2018,중앙대학교 인문콘텐츠연구소,"이 연구는 인공지능 철학과 관련된 기존의 연구의 성과들을 분류, 정리하고 이를 토대로 인공지능인문학 사업단이 수행할 수 있는 앞으로의 연구를 위한 하나의 방향을 제시하는 것을 목적으로 한다. 이를 위해 나는 첫째 논문검색사이트 RISS를 이용하여 ‘인공지능 철학’과 관련된 논문을 최대한 많이 확보하고자 하였다. 검색어는 ‘인공지능, 철학’과 ‘인공지능, 윤리’를 사용하였다. 확보된 논문의 저자, 키워드, 발표년도, 초록 등을 토대로 R의 KoNLP와 Excle을 통하여 논문들을 분석하여 연구동향에 대한 분석의 결과를 시각적으로 나타낼 것이다. 둘째, 연구동향이 갖는 의미를 연구자의 시각에서 재해석하여 의미를 부여하겠다. 그 결과 나는 국내 인공지능 철학연구는 심리철학과 윤리학 기반의 연구로 양분된다는 사실을 도출하였다. 이를 토대로 양분된 연구를 통합된 시각에서 연동하는 것을 ‘인공지능인문학’ 연구단이 이러한 연구의 흐름에 기여할 수 있는 방안으로 제시한다. 그 이유는 존재론 기반이 윤리학 구성의 적실성이다.The purpose of this study is to summarize and classify the results of existing research related to the philosophy of artificial intelligence, presenting a direction for artificial intelligence humanities project teams for their future studies. For this purpose, I searched many papers related to the philosophy of artificial intelligence using the first article search site RISS (Research Information Sharing Service). My search terms were “artificial intelligence, philosophy” and “artificial intelligence, ethics.” The R programming language is a programming language and software environment for statistical computation and visualization. The results of the analysis of research trends will be shown visually, and the significance of the research trends will be reinterpreted from the viewpoint oftheresearcher . As a result, I concluded that domestic research on the philosophy of artificial intelligence is divided into the philosophy of mind and ethics-based research. Therefore, artificial intelligence humanities research can contribute to the flow of suchresearch by linking thetworesearc h types in an integrated way. This is relevant because ontology is based on the relevance of ethics.Artificial Intelligence Humanities, Philosophy of Artificial Intelligence, Ethics of Artificial Intelligence, Philosophy of Mind, Practical Ethics"
1001,인공지능의 발달과 문제점에 대한 고찰 －싱가포르･중국･일본을 중심으로－,최성백 /sung-big choi,2019,동아시아일본학회,"이미 인공지능기술은 전 산업분야로 확산되고 있는 추세이다. Watson은 IBM에서 만든 인공지능으로 종류가 다양하며 의학, 금융, 방송 등에 쓰인다. 또 Allan은 사용자와 대화를 주고받을 수도 있다. 각국의 인공지능기술개발에 대한 관심도 높다. 중국은 AI 학술논문 발표량과 특허출원량이 세계 선두를 차지할 정도로 기초연구와 응용개발 능력을 갖췄다. 미국은 인공지능 우수인재보유 및 상용화 특허에서 세계 선두이다. 올해 초 영어문단을 제시하고 관련 내용에 대한 질문에 답하는 스쿼드(SQuAD) 2.0 언어 이해 분야에서 87.1%를 기록하며 인간의 능력을 넘어섰고, 의료관련 분야에서 인간의 진료기술을 넘어선 분야도 많다. 그러나 4차 산업혁명으로 실업 공포와 인공지능의 자체 문제로 인간사회 지배에 대한 공포 등 다양한 우려도 있다. 현대를 대표하는 인류학자 Yuval Noah Harari은 인공지능의 발달로 일부 지식인과 인공지능(AI)을 사용 못하는 무용자 계급으로 분단되어 과거에 없는 계층사회 도래를 경고하고 있다. 현재 인류는 중요한 기로의 시점에 있다.Artificial intelligence technology is already spreading to all industries. Watson is an artificial intelligence created by IBM, and is used in medicine, finance and broadcasting. Allan can also communicate with the user. There is also high interest in developing artificial intelligence technologies from each country. China has abilities in basic research and application development as its AI academic papers and patent applications dominate the world. The U.S. is the world leader in patents for possessing and commercializing AI talent. It surpassed human capabilities in the field of understanding of the SQuAD 2.0 language, which presents English paragraphs and answers related questions earlier this year, with 87.1 percent, and there are many areas that go beyond human medical care technologies. However, with the fourth industrial revolution, there are also a variety of concerns, including fears of unemployment and fear of human society's dominance due to the artificial intelligence's own problems. Yuval Noah Harari, an anthropologist representing modern times, warns of the arrival of a hierarchical society that has not been in the past, divided by the development of artificial intelligence into the ranks of dancers who are unable to use some intellectuals and artificial intelligence. The human race is now at a critical juncture.すでに人工知能技術は，全産業分野に拡散している。WatsonはIBMで作られた人工知能で種類が多様で，医学，金融，放送などに使われる。また，Allanはユーザと対話を交わすこともできる。各国の人工知能技術開発に対する関心も高い。中国はAI学術論文の発表数と特許出願数が世界トップを占めるほど，基礎研究と応用開発能力を備えている。米国は，人工知能優秀人材保有および商用化特許で世界トップである。今年初め、英語文壇を提示して関連内容についての質問に答えるスクワッド(SQuAD)2.0言語理解の分野で87.1%を記録し、人間の能力を超えており、医療関連分野で人間の診療技術を超えた分野も多い。しかし、4次産業革命で失業の恐怖と人工知能の独自問題で人間社会の支配に対する恐怖など様々な懸念の声がある。現代を代表する人類学者YuvalNoah Harariは人工知能の発達で，一部の知識人と人工知能(AI)を使えない無用者階級に分断され，過去にない階層社会の到来を警告する。現在人類は重要な岐路にあるともいえる。4th Industrial Revolution, Artificial intelligence, Big Data, Internet of Things, unemployment scare, a hierarchical society4次産業革命、人工知能、ビックデータ、IoT、失業の恐怖、階層社会"
1002,인공지능 주체와 미디어 몸들의 세계 ‒ 소셜미디어의 사용자와 게임 유저들의 세계가가지는 의미,이지용 /Jiyong Lee,2020,중앙대학교 인문콘텐츠연구소,"인공지능은 필연적으로 모든 관심 영역에서 인간의 능력을 상회하는 지능을 지향하고, 그렇게 발전하고 있다. 그러기 때문에 인공지능에 대해서 단순히 성찰의 맥락에서만 담론을 전개하기엔 실제 현상적인 부분의 변화폭이 너무 크다. 본고에서는 이러한 변화양상을 통해 나타나는 인공지능 사회의 변화 양상을 소셜 미디어와 게임 유저 경험의 확대인 게이미피케이션을 통해 확인할 수 있을 것이라 판단하였다. 첫 번째로 소셜미디어에서는 주체의 다양성과 의미의 변화가 두드러지는 특징으 로 나타났다고 할 수 있다. 두 번째로 사이버스페이스의 확장과 일상화로 인해서 나타난 게이미피케이션의 확대가 현대 사회의 특징으로 나타남을 알 수 있었다. 이러한 변화의 양상들은 이미 현실에 구현되고 있는 모습들이다. 특히 멀티미디어의 일상화는 주체의 문제와 정체성, 그리고 다양한 의미들을 이전과는 완전히 다른 모습으로 우리의 생활과 인식의 층위들을 해체하게 될 것이다. 그리고 그러한 인식의 전회를 위해서는 먼저, 현상들의 변화 추이를 명확하게 확인하는 것이 중요하다고 할 수 있다.AI continues to outsmart humans in all areas of interest and is constantly developing. It has deeply transformed in terms of actual phenomena. Hence, it is not enough to simply discuss the topic in the context of introspection. The researcher of this paper posits that the changing patterns of AI society can be verified by studying gamification, which is the expansion of social media and game user experiences.
Firstly, in social media, the diversity and meanings of entities have changed remarkably. Secondly, the growth of gamification (caused by the expansion and universalization of cyberspace) has occurred in society.
These shifting patterns are already implemented in reality. In particular, the everyday habits of using multimedia enable us to disassemble the levels of our lives and our perceptions, by modifying the issues and identities of entities, as well as their diverse meanings, in a completely different way. In addition, for a cognitive change, it is important to clearly identify the trends of variations in phenomena.artificial intelligence, media, entity, ego, social media, gamification, hyperconnection"
1003,인공지능 시대에서 키에르케고어의 윤리적 책임,"황종환 /Hwang, JongHwan",2020,중앙대학교 인문콘텐츠연구소,"인간의 인공지능 활동은 인간의 실존적 현실과 연관된다. 인공지능은 실존적 지평(地平)을 확장하는 문화적 활동이다. 실존적 지평의 확장은 삶에 깃들어 있는 절망과 불안의 체험과 함께한다. 실존적 절망과 불안은 양면(兩面)적 특성을 지닌다. 필연, 순간, 유한의 인간 영혼이 자유, 영원, 무한의 높은 실존단계로 나아갈 때 실존적 절망과 불안은 증대된다. 실존적 절망과 불안은 자아를 형성하는 계기가 될 수 있다.
키에르케고어(S. Kierkegaard)는 영원을 사모하는 단독자(單獨者)로서 윤리적 책임을 진지하게 주장한다. 영원을 사모하는 본성의 표현으로서 영원한 존재와 관계는 자신을 형성하는 길이다. 인공지능은 단지 정교한 기계가 아니라 인간문화의 상징적 형식이다. 인간 문화로서 인공지능은 상호작용을 통해 의사소통을 가능하게 한다. 인공지능은 일반적 객관적 문제해결 능력을 갖지만 영혼의 활동으로서 실존하지는 않는다.
인격체로서 인간의 윤리적 역할은 인공지능 혁명의 시대에도 주어져있다. 자아(自我)를 형성하는 과정에서 나타나는 윤리적 책임은 인간만의 독특한 과제다. 윤리적 책임은 독단이나 맹목적 종교의 주장으로부터 인간을 자유롭게 한다. 자아의 형성은 단지 말을 통한 주장이 아니라 윤리적 생활의 열매를 통해 증명되어야 한다. 신뢰할 수 있는 자아는 일생의 걸쳐 표현되는 삶의 번영을 통해 드러난다.Human AI activity is intertwined with existential morality. AI is a symbolic form of broadening human existence. The existential horizon is intimately combined with existential despair and anxiety, which have ambivalent meanings. Existential anxiety and despair increase when the human spirit moves upward to higher spheres of freedom, eternality, and infinity.
S. Kierkegaard asserts that ethical accountability should be taken seriously as a single individual being. The existential ethical atmosphere is proceeding with self-formation. AI, not as a machine, but as a symbolic form of human culture, is to be communicated with others in existential interaction. Existential despair and anxiety for becoming oneself are unique phenomena among human beings.
AI can solve objectified problems, but does not live as a spiritual being. New revolutions in AI’s problem-solving abilities are forcing humans to consider their role in the world, in which human morality has been outstripped by the intelligence of machines. The authentic proof for knowing oneself should be verified through the fruits of moral living, not merely verbal arguments.Artificial intelligence, Ethical responsibility, S. Kierkegaard, Human culture, Scientific symbol."
1004,인공지능철학 관련 연구의 비판적 고찰 - 통합이론 ‘사상한(四象限)’과 관련하여-,허훈 /Heo Hoon,2020,중앙대학교 인문콘텐츠연구소,"거의 모든 학문 영역에서 전(全)방위적으로 인공지능에 대한 연구가 진행되고 있다. 인공지능 관련 철학 연구에 있어서도 많은 연구물들이 나오고 있지만, 상이한 철학적 관점으로 동시에 인공지능 문제에 접근하는 경우가 적지 않다. 대립각을 세웠던 철학사상이 동시에, 동일한 주제에 적용되었을 때 상이한 결론을 도출하기 마련이다. 따라서 ‘상반되는 철학적·윤리학적 관점을 적용했을 때 얻게 될 상이한 결론은 어떻게 극복할 수 있는지?’를 밝히는 것이 선결 과제로 남는다.
본고에서는 이에 대한 또 하나의 대안으로서 통합적 접근(Integrated approach)을 제안한다. 국내외를 막론하고 인공지능에 관한 선행연구에서 통합적 접근법을 사용하는 연구물은 찾기 어렵다. 하지만, 통합적 접근법은 ‘접근법으로서의 개별 철학사상의 한계’, ‘철학적 관점의 차이에 따른 결론의 상이성’을 잘 보여준다. 이에, 통합적인 모델 ‘사상한(四象限)’을 원용하며, 이를 인공지능 문제에 적용·응용할 수 있다는 사실을 적시한다.Research on AI is under way in almost all academic fields. While many investigations have been published in AI-related philosophical studies, there are simultaneously many approaches to AI problems with unique philosophical stances. Different conclusions are often drawn when conflicting philosophical ideas are concurrently applied to the same subject. Thus, it is a prerequisite to reveal the answer to the question, “How can we overcome different conclusions when applying conflicting philosophical perspectives?”This paper proposes an integrated approach as an alternative. It is difficult to find a study that employs an integrated approach in the literature on AI, both at home and abroad. Yet the integrated approach illustrates the limitations of individual philosophical thoughts as an approach and the “differentiation of conclusions based on different philosophical views.” In this paper, I use the integrated model of “all quadrants, all levels” (AQAL). AQAL suggests the need for research into AI, and indicates that it can be applied to AI problems.4th Industrial Revolution, AI(Artificial intelligence), Integrated approach, AQAL(All Quadrant, All Level), Frame"
1005,인공지능 거짓말의 특성 이해 - 거짓말에 대한 윤리학적 담론을 중심으로,김봉제 /Kim Bongje,2020,중앙대학교 인문콘텐츠연구소,"본 연구에서는 인간 거짓말의 특성을 윤리학적 관점에서 분석하여 인공지능 거짓말의 특성을 이해하기 위한 기준을 마련했다. 인간 거짓말에 대한 윤리학적 논쟁은 의무론적 관점, 공리주의적 관점, 덕윤리학적 관점에서 진행되었다. 이 세 관점에서 규정되는 인간의 거짓말을 통해서 볼 때, 인공지능의 거짓말은 인간의 거짓말을 규정한 의무론적, 공리주의적, 덕윤리학적 관점의 제한적인 적용이 가능하다. 하지만 인공지능의 거짓말은 이 세 관점에 의해서 완전하게 규정될 수 없다. 왜냐하면, 인공지능의 머신러닝 과정의 증명불가능성 때문이다. 인공지능의 거짓말은 인간 거짓말의 분석 기준이 되는 의무론적, 공리주의적, 덕윤리학적 데 이터에 의해 이들 각각의 특성을 반영할 수 있다. 하지만 인공지능의 거짓말은 인간 거짓말을 규정할 수 있는 그 이외의 특성을 가지고 있다. 현재로서는 인간 거짓말의 범주를 벗어나는 특성을 규정할 수 있는 표현이 없지만, 인공지능의 거짓말의 범주를 넘어서는 것은 분명하다. 본 논문은 인공지능의 거짓말을 인간의 거짓말과 비교하여 어떤 기준과 관점에서 ‘인공지능의 거짓말’을 규정해야하는 지에 대한 답을 찾아가기 위한 시작이라고 할 수 있다. 이후의 연구에서는 본 논문에서 제시된 윤리학에서의 거짓말과 인공지능 거짓말의 관계를 체계화하는 시도가 필요하다.In this study, the characteristics of human lies were analyzed from an ethical point of view to establish a standard for understanding the characteristics of artificial intelligence lies. The ethical debate on human lies proceeded from the obligatory, utilitarian, and virtuous ethical perspectives. Based on the human lies defined in these three points of view, artificial intelligence lies can be applied in a limited way to the obligatory, utilitarian, and virtuous ethical perspectives that define human lies. However, the lies of artificial intelligence cannot be completely defined by these three perspectives because the machine learning process of artificial intelligence cannot be analyzed. Lies of artificial intelligence can reflect the characteristics of each of these by the deontological, utilitarian, and virtuous ethical data, which are the requirements for the analysis of human lies. However, artificial intelligence lies have certain characteristics that can define human lies. Currently, no expression can define characteristics beyond the scope of human lies, but it is evident that it goes beyond the scope of artificial intelligence lies.
This study can be a stepping stone in finding the standard point of view to define ‘artificial intelligence lies’ by comparing artificial intelligence lies with human lies. In future research, it is necessary to systematize the relationship between human lies and artificial intelligence lies based on the ethics presented in this paper.Artificial intelligence, Lie, Inevitable lies, Right to lie, Big-data"
1006,人工智能犯罪的刑事法律风险与防范,"戴鹏宇 /DAI, PENGYU",2021,동아대학교 법학연구소,"近年来，人工智能技术的发展如火如荼，进入了爆发式增长的黄金时期，弱人工智能时代已然来临。我们正处于新一轮科技革命的前夜，科技的进步总会伴随风险的产生，人工智能发展的不确定性也会带来新的挑战。人工智能所呈现出的深度学习、人机协同、自主操纵等新特征，以及与其他科技的融合创新与聚变发展，使其区别于传统的智能工具而存在，涉人工智能犯罪可能会加剧传统犯罪危害性的广度和深度，甚至出现超出传统犯罪规制的新型主体和行为方式，导致新的犯罪形式产生，必将会对传统的社会伦理观念及现有的法律规范体系产生极大的冲击，刑法应立足于人工智能的发展现状和未来趋势，采取正确、理性的态度应对之中蕴藏的刑事风险。 本文在既有的刑事归责理论范围内，厘清现行刑法在规制涉人工智能犯罪时所面临的挑战，聚焦人工智能技术影响下的刑事风险阶段化的类型治理。并对未来我国刑法应如何合理有效地应对人工智能时代所带来的刑事法律风险与挑战展开分析。明确刑事立法原则，完善相关条文及司法解释，在遵循坚持罪刑法定原则的总体法律底线与谦抑性的内在精神品质的基础上，协同其他部门法共同规制，充分发挥我国刑法在整个法律制度体系内“保护法”和“后盾法”的重要作用，以解决人工智能技术带来的新型法律难题。In recent years, the development of artificial intelligence technology is in full swing, entering the golden period of explosive growth, and the era of weak artificial intelligence has come. We are on the eve of a new round of scientific and technological revolution. The progress of science and technology will always be accompanied by risks, and the uncertainty of the development of artificial intelligence will also bring new challenges. The new features of artificial intelligence, such as deep learning, man-machine cooperation, self-control, etc., as well as the fusion innovation and fusion development with other technologies, make it different from the traditional intelligent tools. Crimes involving artificial intelligence may aggravate the breadth and depth of the harmfulness of traditional crimes, and even lead to new subjects and behavior patterns beyond the traditional criminal regulations, leading to new crimes The emergence of crime forms will have a great impact on the traditional social ethics and the existing legal system. Criminal law should be based on the development status and future trend of artificial intelligence, and adopt a correct and rational attitude to deal with the criminal risks contained in it. Within the scope of the existing criminal imputation theory, this paper clarifies the challenges faced by the current criminal law in regulating crimes involving artificial intelligence, and focuses on the type governance of criminal risks under the influence of artificial intelligence technology. And how to deal with the criminal law risks and challenges brought by the artificial intelligence era reasonably and effectively in the future is analyzed. That is to clarify the principles of criminal legislation, improve the relevant provisions and judicial interpretation, and on the basis of adhering to the overall legal bottom line of the principle of legally prescribed punishment for a crime and the inherent spiritual quality of modesty, we should work together with other department laws to make full use of the important role of China's criminal law as “protection law” and “backing law” in the whole legal system, In order to solve the new legal problems brought by artificial intelligence technology.인공지능 기술이 최근 폭발적으로 발전하면서 인공지능 시대가 도래하고 있다. 우리는 새로운 과학 혁명의 전야(前夜)를 맞아 인공지능 기술의 발전과 응용이 인류에게 새로운 발전의 기회를 제공하게 될 것이지만, 그 과정에서 과학 기술의 발전으로 파생되는 인공지능 관련 범죄도 발생하게 될 것이며, 그 속에 내재된 형사적 위험을 매우 중시해야 한다. AI 관련 범죄는 전통적인 범죄의 위해성의 폭과 깊이를 높이고, 기존의 범죄 규제를 뛰어넘는 새로운 주체와 행위 방식까지 만들어 새로운 범죄 형태를 만들어낼 수 있어 우리나라 전통적인 형사법 체계에도 충격을 줄 수 있다.따라서 형법은 인공지능의 발전 현황과 미래 추세에 입각해 형사입법 원칙을 명확히 하고 관련 조문 및 사법해석을 보완하며 다른 부처법의 공동 규제를 통일해 범죄위험에 대한 올바른 대응으로 인공지능 기술에 따른 새로운 법률문제를 해결해야 한다.Artificial intelligence, Crime, Criminal legal risk Prevention, Countermeasure인공지능, 범죄, 형사법적 위험, 범죄예방, 대책"
1007,윤리적 인공지능을 위한 비도덕 문장 판별 온톨로지 구축에 대한 연구,이청호 /Cheongho Lee,2021,중앙대학교 인문콘텐츠연구소,"데이터에 대한 기존의 윤리적 검증의 방법은 비도덕적인 금지어를 필터링하는 방식으로 이루어졌는데, 이는 복잡하고 다양한 언어의 사용에 효율적으로 적용하기 어렵고 미묘한 비도덕성을 정확하게 판별하기 어렵다는 난점을 지니고 있다. 본 연구는 인공지능 기술을 활용하여 데이터를 분류하고 조직하는 과정에서 편향된 내용을 포함한 비도덕적인 내용들을 선별하게 하는 기준이 되는 도덕 온톨로지(ontology)로서 ‘비도덕 문장 판별 온톨로지’를 제시하고자 한다. 비도덕 문장 판별 온톨로지는 다양한 도덕 판단의 기준을 도입하여 판단 유형에 따른 보다 체계적이고 정확한 분류 작업을 가능하도록 기획되었으며, 형식(Mode), 유형(Type), 대상(Object), 도덕 정서 술어(P, Predicate) 등의 범주로 이루어져 있다. 이러한 온톨로지는 후속 연구를 통해 보다 정교한 형태로 발전시킬 것이며, 보다 내실 있는 윤리 검증의 틀을 제시함으로써 온라인 공간에서 발생할 수 있는 편향되고 비윤리적인 대화 내용의 비도덕성의 정도를 측정할 수 있는 효율적인 윤리 검증 기준을 제공하고자 한다. 이를 통해 다양한 부문에서 활용할 수 있는 한국형 윤리 검증 표준이라는 생태계 구축에 기여할 것으로 생각된다.The previous attempts of developing ethical accreditation of data have been focused on filtering out immoral banned words, which involves the difficulty of implementation in terms of effectivity and accuracy. This study aims to present the “Immoral sentence identification ontology” as a standard for filtering out immoral content including biased content in the process of classifying and organizing data using artificial intelligence technology. The immoral sentence identification ontology was designed to enable more systematic and accurate classification based on ethical theories by introducing various standards of moral judgment. We expect that this ontology will provide an effective standard for measurement of immorality in various everyday conversations and contribute to the establishment of an ecosystem where we can evaluate the degree of immorality of biased and unethical contents under broader circumstances.ethical artificial intelligence, ethical accreditation, moral ontology, banned word, immorality"
1008,망가진 머리: 인공지능과 윤리,이동신 /Dongshin Yi,2018,중앙대학교 인문콘텐츠연구소,"빠르게 다가오는 인공지능의 시대에 인간은 인공지능을 통제 가능한 발달된 도구로 사용할 것인지, 아니면 인간과 공존할 수 있는 동반자로 삼을지 고민해야 할지 모른다. 하지만 두 가지 가능성 중 어떤 선택을 하더라도 인공지능을 다루는 데 있어서 새로운 윤리적 규범이 필요하다는 점은 의심할 여지가 없다. 본고는 인공지능이 매우 성숙한 정신을 가질 수 있고 인간의 삶에 불가결한 존재가 될 거라는 전제를 바탕으로 동반자로서의 인공지능을 대비하는 윤리적 규범이 무엇일지 고찰해본다. 아직 존재하지 않은 존재와의 윤리적 관계를 상정하는 작업이라는 점에서 일종의 생각실험(thought experiment)를 수행하여 논의를 하고자 한다. 실험을 위해 ‘진짜로 망가진 (인공지능) 머리를 어떻게 할 것인가?’라는 질문을 던짐으로써, 윤리적으로 인간과 동등한 관계에 있을 정도로 완전히 성숙한 인공지능이 인간이 설정해 놓은 유용성의 기준에서 벗어나 망가진 상태에 있는 상황을 설정한다. 유사한 상황이 등장하는 아시모프의 소설을 읽어나가면서 본고는 망가진 인공지능에 담긴 새로운 가능성에 주목하고, 이러한 가능성이 새로운 세계로 이어질 수 있음을 강조한다. 결국 인공지능과의 공존을 상상하는 일은 이 세계의 존폐로 이어질 수 있다는 점에서 막대한 윤리적 책임이 담겨있으며, 따라서 본고는 인공지능과 윤리의 논의가 그러한 책임을 인식하는데서 시작한다고 주장한다.The fast approaching age of artificial intelligence requires humans to decide whether this new being will be a highly advanced tool subject to human control and will, or an interdependent companion that humans must learn to coexist with. Either decision should be accompanied by an appropriate set of ethical rules. Believing in the well-formed mind of artificial intelligence, and its full integration with human life, leaves us no room to choose the latter. This paper discusses the ethical possibilities of artificial intelligence by suggesting a thought experiment wherein artificial intelligence is broken, and asking how we should deal with this broken artificial being. Implied in the experiment are two preconditions. The first is that artificial intelligence must be fully mature in order to be on an ethically equal footing as humans. The second is that the term “broken” should be considered free of an anthro- pocentric understanding. By using Isaac Asimov’s stories as an example, the paper incorporates the recent post-humanist discussions of speculative ethics and new materialisms to explain the two preconditions and the irimplications further, and underscores the importance of imagining virtually infinite possibilities that artificial intelligence, broken or not, possesses, independently of human existence. These possibilities mean a new world whose potential to flourish hangs on our decision on artificial intelligence. This paper argues that we consider ethical possibilities of artificial intelligence in such a world-forming scale and with huge responsibilities appropriate to that scale.artificial intelligence, speculative ethics, new materialisms, posthumanism, Isaac Asimov"
1009,"소통, 이성 그리고 인공지능","안윤기 /An, Yoon-Ki",2019,중앙대학교 인문콘텐츠연구소,"이 글에서는 ‘인공지능 시대의 소통’을 그 가능성 측면에서 고찰하였다. 소 통은 인간을 포함한 모든 생명체가 생존과 번영을 위해 여러 수준과 형태로 수행하는 행위인데, 과연 인공지능도 인간과, 또는 다른 인공지능 기계와 소통을 할 수 있을까? 인간의 소통은 ‘언어’라고 하는 탁월한 매체를 통해 수행되며, 이것이 가능했던 것은 인간에게 ‘이성’이라는 지적 능력이 있었기 때문이다. 20세기 중반 이후 개발된 인공지능은 인간의 이성과 언어를 상당히 모방하거나 추월하기도 해서, 누군가는 인공지능과의 대화와 소통이 가능하다고 생각하고, 챗봇의 형태로 그 생각을 구현하기도 했다. 그러나 이 글에서는 그것을 진정한 소통이 아니라고 진단하였다. 자기의식과 자기보존 욕구(영혼)가 없는 한낱 기계는 메시지의 송신자/수신자가 될 수 없기 때문이다.In this article, ‘communication in the era of Artificial Intelligence (= AI)’ was examined in terms of its possibility. Communication is an act performed by all living things, including humans, at various levels and forms for survival and prosperity. Can AI then communicate with humans or other AI machines? Human communication is done through a wonderful medium called ‘language’, which is possible, because humans have a special intellectual power, named as ‘reason’. Because AI-technique developed since the middle of the 20th century imitated or overcame human reason and language, some people thought that it was possible to communicate with AI and realized the idea in the form of a conversation robot (= Chatbot). In this article, however, it is not judged as true communication, because a machine without self-consciousness and the need for self-preservation can not be the sender or recipient of the message.communication, language, reason, AI, self-consciousness"
